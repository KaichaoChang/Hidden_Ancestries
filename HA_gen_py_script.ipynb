{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hidden Ancestries Script\n",
    "\n",
    "### HA : (A, taf, x_guess) -> (x_answer, n_iterations, time)\n",
    "\n",
    "### A generalized function that takes 3 inputs: \n",
    " \n",
    " ## 1. Genetic data in a matrix \"A\" size Nxk containing N SNPs (these are the rows), and k ancestries (these are the columns);\n",
    "\n",
    " ## 2. The total allele frequency called \"taf\" which should be an Nx1 vector\n",
    " \n",
    " ## 3. A starting guess \"x_guess\" which should be a kx1 vector\n",
    "    \n",
    "### and returns 3 outputs:\n",
    "\n",
    " ## 1. The hidden proportions of every ancestry in the data as a kx1 vector\n",
    "    \n",
    " ## 2. The number of iterations that SLSQP did as a scalar value\n",
    "\n",
    " ## 3. The run time of the algoirthm as a scalar value, measured in seconds\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy.optimize import minimize\n",
    "import timeit\n",
    "\n",
    "def HA(A, taf, x_guess):\n",
    "    \n",
    "    # Grab the number of ancestries\n",
    "    k=np.shape(A)[1]\n",
    "    \n",
    "    # Start the clock!\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    # This is the objective function!\n",
    "    def obj_fun(x):\n",
    "        b=0\n",
    "        for i in range(0,k):\n",
    "            b=b + x[i]*A[:,i:(i+1)]\n",
    "        b=b-taf\n",
    "        return np.sum(b**2, axis=0)[0]\n",
    "    \n",
    "    # This is the gradient of the objective function!\n",
    "    def grad_obj_fun(x):\n",
    "\n",
    "        gradvec = np.zeros((k,1))\n",
    "\n",
    "        d=0\n",
    "\n",
    "        for i in range(0,k):\n",
    "            d=d + x[i]*A[:,i:(i+1)]\n",
    "        d=d-taf\n",
    "\n",
    "        for i in range(0,k):\n",
    "            gradvec[i,:] = np.sum(2*A[:,i:(i+1)]*d, axis=0)\n",
    "        return gradvec\n",
    "\n",
    "    # These are wrappers that make our constraints and our bounds\n",
    "\n",
    "    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x,axis=0) -1},)\n",
    "\n",
    "    for i in range(0,k-1):\n",
    "        cons = cons + ({'type': 'ineq', 'fun': lambda x: x[i]},)\n",
    "\n",
    "    bnds = ((0, None),)\n",
    "\n",
    "    for i in range(0,k-1):\n",
    "        bnds = bnds + ((0, None),)\n",
    "\n",
    "    ans_obj = scipy.optimize.minimize(obj_fun, x_guess, method='SLSQP', jac=grad_obj_fun, bounds=bnds, constraints=cons, tol=1e-5)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    time= stop-start\n",
    "    \n",
    "    return ans_obj.x, ans_obj.nit, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize data for testing; define matrix A along with strating guess\n",
    "\n",
    "N=10000 # number of SNPs\n",
    "j=15 # number of ancestries\n",
    "\n",
    "A=np.array(np.random.uniform(low=0, high=1, size=(N,1))) # initialize an array for experimental draws\n",
    "\n",
    "for i in range(1,j):\n",
    "    A=np.hstack((A,np.random.uniform(low=0, high=1, size=(N,1))))\n",
    "\n",
    "# First, we choose an answer! This vector must be Nx1\n",
    "\n",
    "ans=[[0.1], [0.1], [0.1], [0.25], [0.05], [0.1], [0.05], [0.05], [0.01], [0.01], [0.01], [0.01], [0.01], [0.05], [0.1]]\n",
    "\n",
    "mytaf=A@ans # Total allele frequency\n",
    "\n",
    "x_t=(1/j)*np.ones((j,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.09998065, 0.09996509, 0.09996001, 0.24987853, 0.04994105,\n",
      "       0.09981416, 0.04984661, 0.05004293, 0.0098864 , 0.01020446,\n",
      "       0.01017875, 0.01029378, 0.01024066, 0.04989796, 0.09986895]), 24, 0.1558134864853855)\n",
      "our correct answer was chosen to be [[0.1], [0.1], [0.1], [0.25], [0.05], [0.1], [0.05], [0.05], [0.01], [0.01], [0.01], [0.01], [0.01], [0.05], [0.1]]\n"
     ]
    }
   ],
   "source": [
    "what_we_want=HA(A, mytaf, x_t)\n",
    "\n",
    "print(what_we_want)\n",
    "\n",
    "print('our correct answer was chosen to be', ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
