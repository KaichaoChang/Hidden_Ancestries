{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy.optimize import minimize\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(x):\n",
    "    sum_1 = (1-x[1])*(1-x[2])*x[3]*(1-x[4])*(1-x[5])\n",
    "    sum_2 = sum_1 + (1-x[0])*(1-x[2])*(1-x[3])*x[4]*(1-x[5])\n",
    "    sum_3 = sum_2 + (1-x[0])*(1-x[1])*(1-x[3])*(1-x[4])*x[5]\n",
    "    sum_4 = sum_3 + x[0]*(1-x[1])*(1-x[2])*x[4]*x[5]\n",
    "    sum_5 = sum_4 + (1-x[0])*x[1]*(1-x[2])*x[3]*x[5]\n",
    "    sum_6 = sum_5 + (1-x[0])*(1-x[1])*x[2]*x[3]*x[4]\n",
    "    \n",
    "    return -(sum_6**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77622724]\n",
      " [0.31398411]\n",
      " [0.47013231]\n",
      " [0.94712547]\n",
      " [0.27918891]\n",
      " [0.52710747]]\n"
     ]
    }
   ],
   "source": [
    "x_init = np.random.rand(6,1)\n",
    "print(x_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'ineq', 'fun': lambda x:  -(x[1]+x[2]+1-x[3]+x[4]+x[5])+0.0404/0.1685},\n",
    "         {'type': 'ineq', 'fun': lambda x: -(x[0]+x[2]+x[3]+1-x[4]+x[5])+0.0404/0.1685},\n",
    "         {'type': 'ineq', 'fun': lambda x: -(x[0]+x[1]+x[3]+x[4]+1-x[5])+0.0404/0.1685},\n",
    "         {'type': 'ineq', 'fun': lambda x: -(1-x[0]+x[1]+x[2]+1-x[4]+1-x[5])+0.0177/0.1685},\n",
    "         {'type': 'ineq', 'fun': lambda x: -(x[0]+1-x[1]+x[2]+1-x[3]+1-x[5])+0.0177/0.1685},\n",
    "         {'type': 'ineq', 'fun': lambda x: -(x[0]+x[1]+1-x[2]+1-x[3]+1-x[4])+0.0177/0.1685},)\n",
    "\n",
    "for i in range(0,5):\n",
    "    cons = cons + ({'type': 'ineq', 'fun': lambda x: x[i]},)\n",
    "    \n",
    "for i in range(0,5):\n",
    "    cons = cons + ({'type': 'ineq', 'fun': lambda x: x[i]-1},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = ((0, None), (0, None), (0, None), (0, None), (0, None), (0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_obj = scipy.optimize.minimize(obj, x_init, method='SLSQP', bounds=bnds, constraints=cons, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical minimizer is the vector below\n",
      "\n",
      "[2.11982422e-01 6.46318206e-18 7.96931575e-18 1.01927636e+00\n",
      " 5.02635520e-01 7.28397873e-01]\n"
     ]
    }
   ],
   "source": [
    "print('numerical minimizer is the vector below')\n",
    "\n",
    "print()\n",
    "\n",
    "print(np.transpose(ans_obj.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04314890750661111 is the value of the objective function at its min\n"
     ]
    }
   ],
   "source": [
    "print(obj(ans_obj.x), 'is the value of the objective function at its min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* I have not yet checked for mistakes\n",
    "* Did not use true gradient and it appears I may not need to\n",
    "* Computation took <1 second for me. I did not time it, though.\n",
    "* Notice that I am actually minimizing $-f(a)$ where $f(a)$ we defined on the board. (Briefly, it was the square of the big linear sum). Therefore, $a$ is the _minimizer_ of $-f$ hence the _maximizer_ of $f$. So the maximizer equals the minimizer. But the _value_ of $f$ at its _maximizer_ is the negative of what I printed above. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04314890750661111 is the max value of f from the board\n"
     ]
    }
   ],
   "source": [
    "print(-obj(ans_obj.x), 'is the max value of f from the board')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximizer of $\\sqrt{f}$ will be the same as the maximizer of $f$ due to the properties of $f$ (it only takes on nonnegative values) and the fact that $\\sqrt{\\cdot}$ is smooth, etc. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2077231511089005 is the max value of the square root of f from the board\n"
     ]
    }
   ],
   "source": [
    "print((-obj(ans_obj.x))**.5, 'is the max value of the square root of f from the board')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I believe you just need to scale this by the (positive) constant we removed.\n",
    "\n",
    "Again, this is all preliminary and must be checked!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
