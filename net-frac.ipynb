{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy.optimize import minimize\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(x):\n",
    "    sum_1 = (x[7])*(x[8])*x[3]*(x[10])*(x[11])\n",
    "    sum_2 = sum_1 + (x[6])*(x[8])*(x[9])*x[4]*(x[11])\n",
    "    sum_3 = sum_2 + (x[6])*(x[7])*(x[9])*(x[10])*x[5]\n",
    "    sum_4 = sum_3 + x[0]*(x[7])*(x[8])*x[4]*x[5]\n",
    "    sum_5 = sum_4 + (x[6])*x[1]*(x[8])*x[3]*x[5]\n",
    "    sum_6 = sum_5 + (x[6])*(x[7])*x[2]*x[3]*x[4]\n",
    "    \n",
    "    return -sum_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10846042]\n",
      " [0.52235128]\n",
      " [0.40902216]\n",
      " [0.01603309]\n",
      " [0.28220706]\n",
      " [0.04078062]\n",
      " [0.59494419]\n",
      " [0.84284948]\n",
      " [0.72114966]\n",
      " [0.9154053 ]\n",
      " [0.45925293]\n",
      " [0.54923463]]\n"
     ]
    }
   ],
   "source": [
    "x_init = np.random.rand(12,1)\n",
    "print(x_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1),(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'ineq', 'fun': lambda x:  (x[1]+x[2]+x[9]+x[4]+x[5])-0.0402/0.1691},\n",
    "         {'type': 'ineq', 'fun': lambda x: (x[0]+x[2]+x[3]+x[10]+x[5])-0.0402/0.1691},\n",
    "         {'type': 'ineq', 'fun': lambda x: (x[0]+x[1]+x[3]+x[4]+x[11])-0.0402/0.1691},\n",
    "         {'type': 'ineq', 'fun': lambda x: (x[6]+x[1]+x[2]+x[10]+x[11])-0.0174/0.1691},\n",
    "         {'type': 'ineq', 'fun': lambda x: (x[0]+x[7]+x[2]+x[9]+x[11])-0.0174/0.1691},\n",
    "         {'type': 'ineq', 'fun': lambda x: (x[0]+x[1]+x[8]+x[9]+x[10])-0.0174/0.1691},\n",
    "         {'type': 'ineq', 'fun': lambda x: 1-x[0]-x[6]},\n",
    "         {'type': 'ineq', 'fun': lambda x: 1-x[1]-x[7]},\n",
    "         {'type': 'ineq', 'fun': lambda x: 1-x[2]-x[8]},\n",
    "         {'type': 'ineq', 'fun': lambda x: 1-x[3]-x[9]},\n",
    "         {'type': 'ineq', 'fun': lambda x: 1-x[4]-x[10]},\n",
    "         {'type': 'ineq', 'fun': lambda x: 1-x[5]-x[11]},\n",
    "         {'type': 'ineq', 'fun': lambda x: 6-np.sum(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_obj = scipy.optimize.minimize(obj, x_init, method='SLSQP', bounds=bnds, constraints=cons, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical minimizer is the vector below\n",
      "\n",
      "[2.06180618e-02 2.94072420e-08 1.28856982e-02 5.72015925e-02\n",
      " 9.16264696e-01 6.32884806e-02 9.79381939e-01 9.99999967e-01\n",
      " 9.87114302e-01 9.42798408e-01 8.37353043e-02 9.36711520e-01]\n"
     ]
    }
   ],
   "source": [
    "print('numerical minimizer is the vector below')\n",
    "\n",
    "print()\n",
    "\n",
    "print(np.transpose(ans_obj.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7934491565380094 is the value of the objective function at its min\n"
     ]
    }
   ],
   "source": [
    "print(obj(ans_obj.x), 'is the value of the objective function at its min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* I have not yet checked for mistakes\n",
    "* Did not use true gradient and it appears I may not need to\n",
    "* Computation took <1 second for me. I did not time it, though.\n",
    "* Notice that I am actually minimizing $-f(a)$ where $f(a)$ we defined on the board. (Briefly, it was the square of the big linear sum). Therefore, $a$ is the _minimizer_ of $-f$ hence the _maximizer_ of $f$. So the maximizer equals the minimizer. But the _value_ of $f$ at its _maximizer_ is the negative of what I printed above. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7934491565380094 is the max value of f from the board\n"
     ]
    }
   ],
   "source": [
    "print(-obj(ans_obj.x), 'is the max value of f from the board')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I believe you just need to scale this by the (positive) constant we removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010777514823141922 is the max value of f from the board\n"
     ]
    }
   ],
   "source": [
    "print(-(.1685)**5*obj(ans_obj.x), 'is the max value of f from the board')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
